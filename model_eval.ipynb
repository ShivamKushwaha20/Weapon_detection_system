{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0490ceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976017eb",
   "metadata": {},
   "source": [
    "The model is trained on kaggle notebook using the P100 GPU for faster training time. Now using the trained model locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60df0272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded!!\n"
     ]
    }
   ],
   "source": [
    "#Loading the model\n",
    "model = YOLO('models/detect/train/weights/best.pt')\n",
    "print(\"Model Loaded!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69772470",
   "metadata": {},
   "source": [
    "Evaluating the Model on test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d27589c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.133  Python-3.12.0 torch-2.7.0+cpu CPU (AMD Ryzen 5 7520U with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 17.85.6 MB/s, size: 10.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\MPR\\dataset\\test\\labels.cache... 385 images, 3 backgrounds, 0 corrupt: 100%|██████████| 385/385 [00:00<?, ?it/s]\n",
      "c:\\MPR\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 25/25 [02:15<00:00,  5.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        385        416      0.901      0.817      0.915      0.691\n",
      "                 knife        207        216      0.938      0.815      0.921       0.65\n",
      "                pistol        175        200      0.863       0.82      0.908      0.733\n",
      "Speed: 1.9ms preprocess, 337.6ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\MPR\\runs\\detect\\val6\u001b[0m\n",
      "Evalution completed!!\n"
     ]
    }
   ],
   "source": [
    "eval = model.val(data=os.path.abspath('data.yaml'), split='test')\n",
    "print(\"Evalution completed!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9648e05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP50-95:- 0.6913080010952952\n",
      "mAP50:- 0.914596685858754\n",
      "Precision:- [    0.93808     0.86313]\n",
      "Recall:- [    0.81481      0.8198]\n"
     ]
    }
   ],
   "source": [
    "mAP50_95 = eval.box.map\n",
    "mAP50 =  eval.box.map50\n",
    "precision = eval.box.p\n",
    "recall = eval.box.r\n",
    "\n",
    "print('mAP50-95:-', mAP50_95)\n",
    "print('mAP50:-', mAP50)\n",
    "print('Precision:-', precision)\n",
    "print('Recall:-', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ea7e71",
   "metadata": {},
   "source": [
    "Showing the model's object detection capabilites on some test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a6991c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 5 knifes, 276.1ms\n",
      "1: 640x640 1 knife, 276.1ms\n",
      "2: 640x640 1 knife, 276.1ms\n",
      "3: 640x640 1 knife, 276.1ms\n",
      "4: 640x640 1 knife, 276.1ms\n",
      "5: 640x640 2 knifes, 276.1ms\n",
      "6: 640x640 1 knife, 276.1ms\n",
      "7: 640x640 1 knife, 276.1ms\n",
      "8: 640x640 1 knife, 276.1ms\n",
      "9: 640x640 1 knife, 276.1ms\n",
      "10: 640x640 2 pistols, 276.1ms\n",
      "11: 640x640 1 pistol, 276.1ms\n",
      "12: 640x640 2 pistols, 276.1ms\n",
      "13: 640x640 2 pistols, 276.1ms\n",
      "14: 640x640 1 pistol, 276.1ms\n",
      "15: 640x640 2 pistols, 276.1ms\n",
      "16: 640x640 1 pistol, 276.1ms\n",
      "17: 640x640 3 knifes, 1 pistol, 276.1ms\n",
      "18: 640x640 1 pistol, 276.1ms\n",
      "19: 640x640 1 pistol, 276.1ms\n",
      "Speed: 5.0ms preprocess, 276.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mc:\\MPR\\runs\\detect\\predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "rel_path = r'dataset\\test\\images'\n",
    "test_img_count = 20\n",
    "imgs_test = []\n",
    "imgs_list = os.listdir(rel_path)\n",
    "\n",
    "for f in imgs_list:\n",
    "    if imgs_list.index(f) >= test_img_count:\n",
    "        break\n",
    "    imgs_test.append(os.path.join(rel_path, f))\n",
    "\n",
    "\n",
    "results = model(imgs_test, save=True)\n",
    "\n",
    "for r in results:\n",
    "    boxes = r.boxes\n",
    "    masks = r.masks\n",
    "    keypoints = r.keypoints\n",
    "    probs = r.probs\n",
    "    obb = r.obb\n",
    "    r.save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feab6679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
